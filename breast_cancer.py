# -*- coding: utf-8 -*-
"""Breast Cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BEYPg4FolWKZHG0UzzeaTs_N64-oRSHL

Importing Dependencies
"""

import numpy as np   # performing math
import pandas as pd   # to create data frame 
import matplotlib.pyplot as plt  
import sklearn.datasets  # contains the dataset
from sklearn.model_selection import train_test_split

"""Data Preprocessing """

#loading breast cancer data from sklearn
breast_cancer_data = sklearn.datasets.load_breast_cancer()

# in the form of dictionary, needs to be converted to pandas dataframe

#loading the data to pandas dataframe
df= pd.DataFrame(breast_cancer_data.data, columns = breast_cancer_data.feature_names)

df.head()

# adding target column to dtaa frame
df['label'] = breast_cancer_data.target

df.head()

df.shape

df.isna().sum()  # checking null values

df['label'].value_counts()

df.groupby('label').mean()

# 1 --> Benign 
# 0 --> Malignant

X = df.drop(columns = 'label', axis=1)
Y = df['label']

#splittong the data into train and test data
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

"""**Building a Neural Network**"""

# importing tensorflow and keras

import tensorflow as tf   # used to build deep neural networks
tf.random.set_seed(3)  # so that each time you run the code, same accuracy is reached  
from tensorflow import keras

# setting up the layers of Neural Network

model = keras.Sequential([
                          keras.layers.Flatten(input_shape=(30,)),
                          keras.layers.Dense(20, activation='relu'),
                          keras.layers.Dense(2, activation='sigmoid')
])

# flatten ->> input layer  --> converts the data to 1 dimension  
# dense 1 ->> hidden layer  --> number of neurons can be any
# dense 2 ->> output layer  --> 2 neurons is number of classes, 0 or 1

# compiling the neural network
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# trainging the model
history = model.fit(X_train_std, Y_train, validation_split =0.1, epochs =10 )

# epochs is number of times model will go through data

"""Visualising the accuracy and loss"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('model accuracy')
plt.xlabel('accuracy')
plt.ylabel('epochs')


plt.legend(['training data', 'validation data'], loc = 'lower right')

plt.plot(history.history['loss'])
plt.title('model loss')
plt.xlabel('loss')
plt.ylabel('epochs')

# accuracy of the model on test data
loss, accuracy = model.evaluate(X_test_std, Y_test)
print(loss)
print(accuracy)

ip_data = (11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)

ip_data_np = np.asarray(ip_data)

# reshape the numpy array as we are predicting for one data point
ip_reshaped = ip_data_np.reshape(1,-1)

# standardizing the input data
ip_data_std = scaler.transform(ip_reshaped)

prediction = model.predict(ip_data_std)
print(prediction)

prediction_label = [np.argmax(prediction)]
print(prediction_label)

if(prediction_label[0] == 0):
  print('The tumor is Malignant')

else:
  print('The tumor is Benign')

